from __future__ import annotations
import csv, io, json
from datetime import datetime
from typing import List, Dict, Any, Tuple

from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
from rest_framework.views import APIView

from .models import LabResult

# If you want XLSX support, openpyxl should be installed; CSV is primary here.
try:
    import openpyxl
except Exception:
    openpyxl = None

VALID_RESULTS = {"S", "I", "R", "s", "i", "r"}

# ---------- utilities ----------
def _clean(s: Any) -> str:
    return (str(s).strip() if s is not None else "").strip()

def _try_parse_date(s: str) -> str:
    s = _clean(s)
    if not s:
        return ""
    for fmt in ("%Y-%m-%d", "%d/%m/%Y", "%d-%m-%Y", "%Y/%m/%d", "%m/%d/%Y"):
        try:
            dt = datetime.strptime(s, fmt)
            return dt.strftime("%Y-%m-%d")
        except Exception:
            continue
    # Last resort: try ISO parse
    try:
        dt = datetime.fromisoformat(s)
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return s  # leave as-is; downstream code may accept it or fail

# ---------- WHONET detection & mapping ----------
WHONET_SIGNALS = {"LAB NO", "PATIENT ID", "WHONET", "ISOLATE", "SPECIMEN", "SPECIMEN DATE"}

# small antibiotic header aliases mapping (extend as needed)
ANTIBIOTIC_ALIAS = {
    "CIP": "Ciprofloxacin", "CIPRO": "Ciprofloxacin", "CIPROFLOXACIN": "Ciprofloxacin",
    "CTX": "Ceftriaxone", "CRO": "Ceftriaxone", "CEFTRIAXONE": "Ceftriaxone",
    "GEN": "Gentamicin", "GENTAMICIN": "Gentamicin",
    "AMX": "Amoxicillin", "AMOX": "Amoxicillin", "AMOXICILLIN": "Amoxicillin",
    # add more mappings if you have common WHONET short codes
}

def _is_whonet_header(headers: List[str]) -> bool:
    H = {(_ or "").strip().upper() for _ in headers}
    # presence of any strong signal -> WHONET
    if H & WHONET_SIGNALS:
        return True
    # if many columns and many unknown drug-like columns, also treat as WHONET
    expected = {"patient_id","organism","host_type","facility","test_date","antibiotic","ast_result"}
    other = [h for h in H if h not in expected and h and len(h) > 1]
    return len(other) >= 8

def _map_header_label(h: str) -> str:
    if not h: return ""
    hu = h.strip().upper()
    if hu in ("PATIENT ID","PATIENT_ID","ID"): return "patient_id"
    if hu in ("SPECIMEN DATE","SPECIMEN_DATE","ISOLATION DATE","DATE"): return "test_date"
    if hu in ("SPECIMEN","SPECIMEN TYPE","SPECIMEN_TYPE"): return "specimen_type"
    if hu in ("ORGANISM","ISOLATE","ORGANISM IDENTIFICATION"): return "organism"
    if hu in ("HOST TYPE","HOST_TYPE","HOST"): return "host_type"
    if hu in ("LAB","FACILITY","LAB NAME","FACILITY NAME"): return "facility"
    if hu in ("PATIENT TYPE","INPATIENT/OUTPATIENT"): return "patient_type"
    if hu in ("SEX","GENDER"): return "sex"
    if hu in ("AGE","PATIENT AGE"): return "age"
    if hu in ("ANIMAL SPECIES","ANIMAL_SPECIES","SPECIES"): return "animal_species"
    if hu in ("ENVIRONMENT TYPE","ENVIRONMENT_TYPE"): return "environment_type"
    # map common antibiotic short codes
    if hu in ANTIBIOTIC_ALIAS:
        return ANTIBIOTIC_ALIAS[hu]
    # otherwise return header as-is (treat as antibiotic label)
    return h.strip()

# ---------- parsers ----------
def _parse_csv_bytes(b: bytes) -> Tuple[List[Dict[str,Any]], List[str]]:
    """Parse normal template CSV (long format: one antibiotic per row) into row dicts."""
    text = b.decode("utf-8", errors="replace")
    reader = csv.DictReader(io.StringIO(text))
    rows = []
    errors = []
    for i, r in enumerate(reader, start=1):
        try:
            # canonicalize keys to expected names
            row = {k.strip(): _clean(v) for k,v in r.items()}
            # normalize date
            row["test_date"] = _try_parse_date(row.get("test_date",""))
            rows.append(row)
        except Exception as e:
            errors.append(f"row {i}: {e}")
    return rows, errors

def _parse_whonet_csv_bytes(b: bytes) -> Tuple[List[Dict[str,Any]], List[str]]:
    """
    Parse a WHONET-style wide CSV: one isolate per row with many antibiotic columns.
    Output a list of normalized rows in the long format expected by DB ingestion:
     patient_id, sex, age, specimen_type, organism, antibiotic, ast_result, test_date, host_type, facility, patient_type, animal_species, environment_type
    """
    text = b.decode("utf-8", errors="replace")
    rdr = csv.reader(io.StringIO(text))
    all_rows = list(rdr)
    if not all_rows:
        return [], ["empty file"]

    headers = [h.strip() for h in all_rows[0]]
    mapped = [_map_header_label(h) for h in headers]

    # find index positions for metadata columns
    meta_idx = {}
    for idx, m in enumerate(mapped):
        mm = (m or "").lower()
        if mm in ("patient_id","sex","age","specimen_type","organism","test_date","host_type","facility","patient_type","animal_species","environment_type"):
            meta_idx[mm] = idx

    rows_out = []
    errors = []
    for row_no, raw in enumerate(all_rows[1:], start=2):
        # ignore empty rows
        if not any(cell.strip() for cell in raw):
            continue
        try:
            # basic metadata extraction
            def get_meta(k):
                idx = meta_idx.get(k)
                return _clean(raw[idx]) if (idx is not None and idx < len(raw)) else ""
            base = {
                "patient_id": get_meta("patient_id"),
                "sex": get_meta("sex"),
                "age": get_meta("age"),
                "specimen_type": get_meta("specimen_type"),
                "organism": get_meta("organism"),
                "test_date": _try_parse_date(get_meta("test_date")),
                "host_type": get_meta("host_type"),
                "facility": get_meta("facility"),
                "patient_type": get_meta("patient_type"),
                "animal_species": get_meta("animal_species"),
                "environment_type": get_meta("environment_type"),
            }
            # any header not mapped to metadata is treated as antibiotic column
            for col_idx, hdr in enumerate(headers):
                label = mapped[col_idx]
                # skip metadata columns
                if (label or "").lower() in ("patient_id","sex","age","specimen_type","organism","test_date","host_type","facility","patient_type","animal_species","environment_type"):
                    continue
                val = _clean(raw[col_idx]) if col_idx < len(raw) else ""
                if not val:
                    continue
                # if the cell holds S/I/R (or synonyms), record it
                if val.strip().upper() in VALID_RESULTS:
                    # antibiotic name: prefer mapped label, else header text
                    ab_name = label if label and label not in ("", hdr) else hdr.strip()
                    rows_out.append({
                        **base,
                        "antibiotic": ab_name,
                        "ast_result": val.strip().upper()
                    })
                # sometimes WHONET uses numeric codes; ignore for now
        except Exception as e:
            errors.append(f"row {row_no}: {e}")
    return rows_out, errors

# Optional Excel parser: produce a CSV-like list of dicts
def _parse_xlsx_bytes(b: bytes) -> Tuple[List[Dict[str,Any]], List[str]]:
    if openpyxl is None:
        return [], ["openpyxl not installed"]
    try:
        wb = openpyxl.load_workbook(filename=io.BytesIO(b), read_only=True, data_only=True)
        ws = wb.active
        rows = list(ws.values)
        if not rows:
            return [], ["empty xlsx"]
        headers = [(_ or "").strip() for _ in rows[0]]
        text_io = io.StringIO()
        writer = csv.writer(text_io)
        writer.writerow(headers)
        for r in rows[1:]:
            writer.writerow([("" if v is None else str(v)) for v in r])
        return _parse_csv_bytes(text_io.getvalue().encode("utf-8"))
    except Exception as e:
        return [], [str(e)]

# ---------- main view ----------
@method_decorator(csrf_exempt, name="dispatch")
class CSVUploadOpenView(APIView):
    permission_classes = [AllowAny]

    def post(self, request, *args, **kwargs):
        f = request.FILES.get("file")
        if not f:
            return Response({"status": "error", "detail": "No file uploaded."}, status=400)

        content = f.read()
        created = 0
        errors: List[str] = []
        rows: List[Dict[str,Any]] = []

        # detect Excel by PK header
        is_xlsx = bool(content[:4] == b'PK\x03\x04')

        # Try excel first if it looks like xlsx
        if is_xlsx:
            rows, errs = _parse_xlsx_bytes(content)
            errors.extend(errs)
        else:
            # quick header inspection for detection
            first_line = content.decode("utf-8", errors="replace").splitlines()[0] if content else ""
            hdrs = [h.strip() for h in first_line.split(",")] if first_line else []
            try:
                if _is_whonet_header(hdrs):
                    rows, errs = _parse_whonet_csv_bytes(content)
                    errors.extend(errs)
                else:
                    rows, errs = _parse_csv_bytes(content)
                    errors.extend(errs)
            except Exception as e:
                return Response({"status":"error","detail": f"Could not parse upload: {e}"}, status=400)

        # Basic validation: rows must contain required fields for insertion
        if not rows:
            return Response({"status":"error","detail":"No rows parsed from file.", "friendly":"The file could not be parsed. Please save as CSV UTF-8 or XLSX and try again."}, status=400)

        created = 0
        row_errors = []
        for i, r in enumerate(rows, start=1):
            try:
                # minimal required fields:
                required = ["organism","antibiotic","ast_result"]
                if not all(_clean(r.get(k,"")) for k in required):
                    row_errors.append(f"row {i}: missing required fields")
                    continue

                # create LabResult: adapt field names if your model uses different ones
                lr = LabResult(
                    patient_id = _clean(r.get("patient_id","")),
                    sex = _clean(r.get("sex","")),
                    age = _clean(r.get("age","")) or None,
                    specimen_type = _clean(r.get("specimen_type","")),
                    organism = _clean(r.get("organism","")),
                    test_date = _clean(r.get("test_date","")) or None,
                    host_type = _clean(r.get("host_type","")),
                    facility = _clean(r.get("facility","")),
                    patient_type = _clean(r.get("patient_type","")),
                    animal_species = _clean(r.get("animal_species","")),
                    environment_type = _clean(r.get("environment_type","")),
                    antibiotic = _clean(r.get("antibiotic","")),
                    ast_result = _clean(r.get("ast_result","")).upper(),
                )
                lr.save()
                created += 1
            except Exception as e:
                row_errors.append(f"row {i}: {e}")

        errors.extend(row_errors)
        return Response({"status":"ok","created":created,"errors":errors})
